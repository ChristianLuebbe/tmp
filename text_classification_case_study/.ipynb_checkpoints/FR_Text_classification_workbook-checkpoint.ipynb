{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification des textes :: Vue d'ensemble\n",
    "\n",
    "## Objectif \n",
    "\n",
    "Nous allons construire un détecteur de spam qui apprend à marquer les nouveaux courriels non vus comme spam ou non spam.\n",
    "\n",
    "On va montrer au détecteur des **exemples de courriels de spam** (par exemple, signalés par les utilisateurs) et **d'exemples de courriels normaux** (non spam). \n",
    "\n",
    "Nous travaillons donc avec un exemple **d'apprentissage supervisé**.\n",
    "\n",
    "## Données\n",
    "\n",
    "Nous utiliserons le corpus d'emails publics de [SpamAssassin] (https://spamassassin.apache.org/).   \n",
    "Cet ensemble de données contient ~6'000 emails étiquetés dont ~30% sont des spams.  \n",
    "Si vous souhaitez en savoir plus sur cet ensemble de données, consultez [ce lien](https://spamassassin.apache.org/old/publiccorpus/).  \n",
    "(*Note : les ensembles de données de texte sont appelés corpus et les échantillons sont appelés documents.*) \n",
    "\n",
    "L'ensemble de données a été téléchargé pour vous et est disponible dans le dossier *data*.\n",
    "\n",
    "## Aperçu du Notebook\n",
    "\n",
    "* **Charger les données**\n",
    "* **Prétraitement du texte**\n",
    "* **Exploration des données** \n",
    "* **Extraction de caractéristiques** \n",
    "* **Construire un détecteur de spam** \n",
    "* **Qu'a appris notre modèle ? Analyse des erreurs** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des textes  :: Détection de spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = tools.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions le nombre d'échantillons par classe dans les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_class_frequency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, regardons quelques lignes de l'ensemble de données.\n",
    "\n",
    "**Note** : L'étiquette est 0 pour le non-spam et 1 pour le _spam_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you rerun this cell then you get a different set of samples displayed\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prétraitement du texte\n",
    "\n",
    "Un bon prétraitement de texte est une partie essentielle de tout projet NLP !\n",
    "\n",
    "Notre objectif ici est de construire un modèle qui distingue le non-spam du spam.   \n",
    "L'idée ici est de \"nettoyer\" et de \"normaliser\" le texte brut avant de le soumettre à notre modèle d'apprentissage automatique.   \n",
    "Nous devons conserver autant de mots \"informatifs\" que possible, tout en éliminant les mots \"uniformes\". L'élimination du contenu inutile, c'est-à-dire le \"bruit\", de nos textes contribuera à améliorer la précision de nos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "Prenez quelques minutes pour regarder le texte brut.  \n",
    "    \n",
    "__Q1.__ Quelles sont, selon vous, les parties du texte qui devraient être supprimées pour le rendre lisible ?\n",
    "    \n",
    "__Q2.__ Comment les parties que nous venons d'enlever pour nettoyer le texte, peuvent-elles encore être utiles pour distinguer le spam du non-spam ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vos réponses\n",
    "\n",
    "__Q1.__ \n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* ...\n",
    "\n",
    "\n",
    "__Q2.__   \n",
    "\n",
    "-   \n",
    "- ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction *clean_corpus* ci-dessous prendra en charge les parties soulevées par la Question 1.\n",
    "\n",
    "Pour les idées de la question 2, nous créerons de nouvelles fonctionnalités et étudierons leurs effets dans la sous-section  **What about \"spammish\" signatures?**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tools.clean_corpus(df)\n",
    "\n",
    "print(\"Data cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons quelques exemples \"nettoyés\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.show_clean_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données : : Comment les spams se distinguent-ils ?\n",
    "\n",
    "### Mots fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels mots distinguent le spam du non-spam ? Peut-on identifier les mots d'un texte qui sont les plus informatifs sur son sujet ?\n",
    "\n",
    "Trouvons les 10 mots les plus fréquents dans le spam et le non-spam et comparons-les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_most_common_words(df=df, N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "Q1.__ Parmi les 10 mots \"spammées\" les plus fréquents, lesquels sont propres à cette classe ?\n",
    "\n",
    "Q2.__ Lesquels des 10 mots \"non spammées\" les plus fréquents sont uniques à cette classe ?\n",
    "     \n",
    "Q3.__ Parmi les mots qui apparaissent dans les deux listes, lesquels sont probablement encore utiles pour distinguer les classes ?\n",
    "    \n",
    "Q4.__ Lesquels ne le sont probablement pas ?\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vos réponses\n",
    "\n",
    "__Q1.__ **Les 10 mots \"spammées\" les plus fréquents**: \n",
    "\n",
    "* \n",
    "* \n",
    "\n",
    "__Q2.__ **Les 10 mots non-\"spammées\" les plus fréquents**:\n",
    "\n",
    "* \n",
    "* \n",
    "\n",
    "__Q3.__ **Présente dans les deux listes mais pourrait être utile pour les distinctions**:\n",
    "\n",
    "* \n",
    "* \n",
    "\n",
    "\n",
    "__Q4.__ **Présente dans les deux listes mais peu susceptibles d'être utiles**:\n",
    "\n",
    "* \n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Changez `N=10` en `N=30` et comparez le résultat.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_most_common_words(df=df, N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vos observations\n",
    "\n",
    "Plus nous utilisons de mots-clés, plus nous obtenons de chevauchements entre les classes.  \n",
    "Cependant, des mots comme _email_ ou _free_ sont toujours beaucoup plus fréquents dans la classe **spam**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que peut-on dire des indicateurs ou signatures de \"spam\" ? ?\n",
    "\n",
    "* Les spams contiennent-ils plus de balises HTML ? \n",
    "* Les non-spams contiennent-ils plus d'URL et d'adresses e-mail ? \n",
    "* Les spams sont-ils plus longs que les non-spams ? \n",
    "* ...\n",
    "\n",
    "C'est ce que nous allons découvrir !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tools.get_features(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction de caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les ordinateurs ne comprennent pas le langage naturel. Alors, comment représenter le texte ?\n",
    "\n",
    "L'un des modèles les plus simples mais efficaces et couramment utilisés pour représenter le texte pour l'apprentissage automatique est le modèle ***Bag of Words*** ([documentation en ligne](https://en.wikipedia.org/wiki/Bag-of-words_model)). Lorsqu'on utilise ce modèle, on écarte la majeure partie de la structure du texte d'entrée (ordre des mots, chapitres, paragraphes, phrases et mise en forme) et on ne compte que la fréquence d'apparition de chaque mot dans chaque texte. Le fait d'écarter la structure et de ne compter que les occurrences des mots conduit à l'image mentale de la représentation du texte comme un \"sac\".  \n",
    "\n",
    "**Exemple:** Soit notre corpus jouet contenant quatre documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ corpus = ['I\\;enjoy\\;paragliding.',  $  \n",
    "$\\hspace{2cm}'I\\;like\\;NLP.',$  \n",
    "$\\hspace{2cm}'I\\;like\\;deep\\;learning.',$  \n",
    "$\\hspace{2cm}'O\\;Captain!\\;my\\;Captain!']$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.show_bag_of_words_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words a converti tous les documents en vecteurs numériques. Chaque colonne représente un mot du corpus et chaque ligne un des quatre documents. La valeur dans chaque cellule représente le nombre de fois que ce mot apparaît dans un document spécifique. Par exemple, dans le quatrième document, le mot `capitain` apparaît deux fois et les mots `my` et `O` apparaissent une fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construisons notre détecteur de spam\n",
    "\n",
    "(Dans la section précédente, nous avons vu comment effectuer le prétraitement du texte et l'extraction de caractéristiques du texte.)  \n",
    "Nous sommes maintenant prêts à construire notre modèle d'apprentissage automatique pour détecter les spams.  \n",
    "Nous allons utiliser un **simple classificateur de régression logistique** ([documentation en ligne](https://en.wikipedia.org/wiki/Logistic_regression)).\n",
    "\n",
    "Tout d'abord, nous divisons les données en deux ensembles : l'ensemble `train` et l'ensemble `test`. Rappelez-vous:\n",
    "- Nous utiliserons l'ensemble `train` pour adapter notre modèle.  \n",
    "- **Notez que nous n'avons pas créé d'ensemble de données de validation**. En fait, nous allons utiliser la **validation croisée (5-fold)**. Ainsi, les ensembles de validation sont **automatiquement créés en interne**.  \n",
    "- L'ensemble de `test` sera utilisé pour évaluer la performance de notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ligne de base\n",
    "\n",
    "70.3% des échantillons sont des non-spams.   \n",
    "**Ce modèle de base naïf atteindrait 70+% en faisant très peu.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test splitting\n",
    "df_train, df_test = tools.train_test_split_(df)\n",
    "\n",
    "# Fit model on the train data\n",
    "model = tools.fit_model(df_train)\n",
    "\n",
    "# Print predictions on test set\n",
    "tools.plot_confusion_matrix(df_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrices**  \n",
    "\n",
    "Les matrices de confusion sont un bon moyen d'évaluer les performances des modèles de classification.  \n",
    "Les rangées (rows) correspondent aux vraies classes et les colonnes aux classes prédites.  \n",
    "Les entrées sur la diagonale principale de la matrice de confusion correspondent aux prédictions correctes tandis que les autres cellules nous indiquent le nombre d'erreurs de notre modèle ([documentation en ligne]((https://en.wikipedia.org/wiki/Confusion_matrix))).\n",
    "\n",
    "* La première ligne représente les courriers non spam :  \n",
    "On voit **1'187 ont été correctement classés comme 'non-spam'**,  \n",
    "tandis que **29 (~2,3%) ont été mal classés comme 'spam'**.\n",
    "* La deuxième ligne représente les messages de spam :  \n",
    "On voit **437 ont été correctement classés comme 'spam'**,  \n",
    "tandis que **13 (~2,8%) ont été mal classés comme 'non-spam'**.\n",
    "\n",
    "Notre modèle s'est bien comporté !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qu'est-ce que notre modèle a appris des données?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle de régression logistique a appris **quels mots sont les plus indicatifs** de non-spam et quels mots sont les plus indicatifs de spam.  \n",
    "* **Les coefficients positifs sur la droite** correspondent aux mots qui, _selon le modèle_, **sont indicatifs de spam**.  \n",
    "* **Les coefficients négatifs à gauche** correspondent à des mots qui, _selon le modèle_, **sont indicatifs de non-spam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.visualize_coefficients(model, n_top_features=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "__Q1.__ Selon le modèle, quels mots sont des indicateurs forts de non-spam, respectivement de spam ?  \n",
    "    \n",
    "__Q2.__ Se recoupent-ils avec les résultats de notre analyse ?    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vos réponses\n",
    "\n",
    "Q1.  \n",
    "\n",
    "Q2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des erreurs : : Où notre modèle échoue-t-il ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant analyser les courriers mal classés pour mieux comprendre où le modèle n'a pas réussi à faire des prédictions correctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.error_analysis(df_test, model, doc_nbr=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Let's change the `doc_nbr`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.error_analysis(df_test, model, doc_nbr=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml_M1] *",
   "language": "python",
   "name": "conda-env-adsml_M1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
